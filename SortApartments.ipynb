{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and other functions\r\n",
    "import os\r\n",
    "import re\r\n",
    "import time\r\n",
    "import random\r\n",
    "import requests\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from datetime import datetime\r\n",
    "import plotly.express as px\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn import preprocessing \r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_apartment_data(df):\r\n",
    "    \"\"\"Clean up the apartments raw data.\"\"\"\r\n",
    "    # Start by dropping any duplicate entries.\r\n",
    "    df = df.drop_duplicates()\r\n",
    "    \r\n",
    "    # Square footage comes as \"[0-9] - [0-9] sq ft\"\r\n",
    "    # 1. Strip commas and \" sq ft\", then split the remaining into three columns, titled \"min_square_footage\", \"hyphen\", and \"max_square_footage.\"\r\n",
    "    # 2. Drop the hyphen column.\r\n",
    "    # 3. If the max column is null, fill it with whatever's in the min column.\r\n",
    "    df[['min_square_footage', 'hyphen', 'max_square_footage']] = df['square_footage'].str.replace(' sq ft', '').str.replace(',', '').str.split(expand=True)\r\n",
    "    df = df.drop(['square_footage', 'hyphen'], 1)\r\n",
    "    df['max_square_footage'][df['max_square_footage'].isnull()] = df['min_square_footage'].loc[df['max_square_footage'].isnull()]\r\n",
    "\r\n",
    "    # Repeat the above process with the price column\r\n",
    "    df['price'] = df['price'].str.replace('Call for Rent', '')\r\n",
    "    df[['min_price', 'hyphen', 'max_price']] = df['price'].str.split(expand=True)\r\n",
    "    df = df.drop(['price', 'hyphen'], 1)\r\n",
    "    df['max_price'][df['max_price'].isnull()] = df['min_price'].loc[df['max_price'].isnull()]\r\n",
    "\r\n",
    "    # Strip nonnumeric characters\r\n",
    "    for column in ['beds', 'baths', 'min_price', 'max_price']:\r\n",
    "        df[column] = df[column].str.replace(r'[A-Za-z ,$]*', '')\r\n",
    "\r\n",
    "    # Convert data to numeric\r\n",
    "    for column in ['beds', 'baths', 'min_price', 'max_price', 'max_square_footage', 'min_square_footage']:\r\n",
    "        df[column] = pd.to_numeric(df[column])\r\n",
    "\r\n",
    "    # Remove studio apartments\r\n",
    "    df = df[~df['beds'].isnull()]\r\n",
    "\r\n",
    "    # Fill in missing availability data\r\n",
    "    df['availability'][df['availability'].isnull()] = 'No availability provided'\r\n",
    "\r\n",
    "    # Price per square foot\r\n",
    "    df['max_ppf'] = df['max_price'] / df['max_square_footage']\r\n",
    "    df['min_ppf'] = df['min_price'] / df['min_square_footage']\r\n",
    "\r\n",
    "    return(df)\r\n",
    "\r\n",
    "\r\n",
    "def get_commute_lengths(origins, destination, api_key, sleep_time=0.5):\r\n",
    "    \"\"\"\r\n",
    "    Hit the google Distance Matrix api for the distances between origins and destinations.\r\n",
    "    More specifically, take a list of origins and a list of destinations and return an array of json objects.\r\n",
    "    We included a half a second sleep time by default to avoid from overwhelming the page.\r\n",
    "    \"\"\"\r\n",
    "    # Empty array to store json distance objects\r\n",
    "    distance_objects = []\r\n",
    "\r\n",
    "    # This is the url to access the maps api, we need to append the origin and destination as well as api key\r\n",
    "    distance_matrix_url = 'https://maps.googleapis.com/maps/api/distancematrix/json?'\r\n",
    "\r\n",
    "    # For each origin in our set of origins and for each destination in our set of destinations:\r\n",
    "    #    search for the distance between that and each destination.\r\n",
    "    for origin in origins:\r\n",
    "        time.sleep(sleep_time)\r\n",
    "        print(f\"Searching for the information about the drive from {origin} to {destination}.\")\r\n",
    "        search_result = requests.get(distance_matrix_url + 'origins=' + origin + '&destinations=' + destination + '&key=' + api_key)\r\n",
    "        distance_objects.append(search_result.json())\r\n",
    "    \r\n",
    "    return(distance_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\r\n",
    "# Import Data #\r\n",
    "###############\r\n",
    "# Since we date the files we save, open the last file in the directory.\r\n",
    "directory_location = 'data/scraped_data/'\r\n",
    "newest_file = os.listdir(directory_location)[-1]\r\n",
    "df_0 = pd.read_csv(directory_location + newest_file)\r\n",
    "print(\"Retrieving information from\", newest_file)\r\n",
    "\r\n",
    "##############\r\n",
    "# Clean Data #\r\n",
    "##############\r\n",
    "df_cleaned = clean_apartment_data(df_0)\r\n",
    "df_cleaned\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################\r\n",
    "# Append Commute Lengths #\r\n",
    "##########################\r\n",
    "\r\n",
    "# \r\n",
    "# \r\n",
    "# \r\n",
    "# \r\n",
    "destination = ['210 Carnegie Center, Princeton, NJ']\r\n",
    "origins = df_cleaned['residence_address'].unique()\r\n",
    "commute_json_objects = get_commute_lengths(origins=origins, destination=destination, api_key= #insert api key here)\r\n",
    "distances = [d['rows'][0]['elements'][0]['duration']['value'] for d in commute_json_objects]\r\n",
    "commute_durations = pd.DataFrame({'residence_address' : origins, 'commute_in_seconds' : distances})\r\n",
    "# commute_durations.to_csv('data/commute_length.csv', index=False) # uncommment to save a csv of the distance set\r\n",
    "df = df_cleaned.merge(commute_durations, on=['residence_address'], how='left')\r\n",
    "df['commute_in_minutes'] = df['commute_in_seconds'] / 60\r\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Scale the data so we can use come up with the 'apartment rating' \"\"\"\r\n",
    "\r\n",
    "# Scaler\r\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\r\n",
    "\r\n",
    "# Invert these to get the apartment rating components going in the same direction\r\n",
    "for column in [\r\n",
    "    'min_price', 'max_price', \r\n",
    "    # 'commute_in_minutes'\r\n",
    "    ]:\r\n",
    "    df[column + '_inv'] = 1 / df[column]\r\n",
    "\r\n",
    "scaled_data = pd.DataFrame(min_max_scaler.fit_transform(df[['min_square_footage', 'max_square_footage', 'min_price', 'max_price', 'min_ppf', 'max_ppf',\r\n",
    "                                                            # 'commute_in_minutes', \r\n",
    "                                                            'min_price_inv', 'max_price_inv', \r\n",
    "                                                            # 'commute_in_minutes_inv'\r\n",
    "                                                            ]]), \r\n",
    "                            columns=['scaled_' + c for c in ['min_square_footage', 'max_square_footage', 'min_price', 'max_price', 'min_ppf', 'max_ppf',\r\n",
    "                                    #  'commute_in_minutes', \r\n",
    "                                     'min_price_inv', 'max_price_inv',\r\n",
    "                                    #   'commute_in_minutes_inv'\r\n",
    "                                      ]])\r\n",
    "df = df.join(scaled_data)\r\n",
    "df['apartment_rating'] = (((df['scaled_min_square_footage']) ** 2) + ((df['scaled_min_price_inv']) ** 2) + ((df['scaled_commute_in_minutes_inv']) ** 2)) ** (1/2)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Apartment features should be filled in as you look at the residences. I haven't looked into automating that yet.\"\"\"\r\n",
    "\r\n",
    "# Does the building have a pool?\r\n",
    "df['pool'] = 'unknown'\r\n",
    "df.loc[df['residence_name'].isin([\r\n",
    "                                    # insert residence names here\r\n",
    "                                    ]), ['pool']] = 'y'\r\n",
    "df.loc[df['residence_name'].isin([\r\n",
    "                                    # insert residence names here\r\n",
    "                                    ]), ['pool']] = 'n'\r\n",
    "\r\n",
    "df['patio'] = 'unknown'\r\n",
    "df.loc[df['residence_name'].isin([\r\n",
    "                                  # insert residence names here\r\n",
    "                                    ]), ['patio']] = 'y'\r\n",
    "df.loc[df['residence_name'].isin([\r\n",
    "                                  # insert residence names here\r\n",
    "                                    ]), ['patio']] = 'n'\r\n",
    "\r\n",
    "# df.loc[[302], ['patio']] = 'n'\r\n",
    "df['laundry'] = 'unknown'\r\n",
    "df.loc[df['residence_name'].isin([\r\n",
    "                                # insert residence names here\r\n",
    "                                    ]), ['laundry']] = 'communal'\r\n",
    "df.loc[df['residence_name'].isin([\r\n",
    "                                    # insert residence names here\r\n",
    "                                    ]), ['laundry']] = 'in unit'\r\n",
    "df.loc[df['residence_name'].isin(['Cedar Manor', 'Pike Run Meadows', 'Summerfields Lofts', 'The Grove Somerset', 'Merrieworld', 'Plaza Square Apartment Homes', 'The Aspire']\r\n",
    "), ['dishwasher']] = 'y'\r\n",
    "\r\n",
    "# Slice the data frame to get specific apartments and put them in our ploting data frame\r\n",
    "pf = df[\r\n",
    "        # insert filters here\r\n",
    "        ]\r\n",
    "        \r\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D interactive chart\r\n",
    "# Add whichever columns to the hover data to see it on mouseover\r\n",
    "fig = px.scatter(pf, \r\n",
    "                    x = 'min_square_footage',\r\n",
    "                    # x='apartment_rating', \r\n",
    "                    # y = 'scaled_min_price',\r\n",
    "                    y = 'min_price',\r\n",
    "                    color='residence_name', \r\n",
    "                    # size='commute_in_minutes',\r\n",
    "                    # text = 'model_name',\r\n",
    "                    # title = 'Apartments: Square Footage by Price',\r\n",
    "                    # labels={'min_price' : 'Price', 'min_square_footage' : 'Square Footage'},\r\n",
    "                    hover_data=['model_name', 'min_ppf'],\r\n",
    "                    )\r\n",
    "# fig.update_traces(textposition='top center')\r\n",
    "\r\n",
    "fig.show()\r\n",
    "# fig.write_html('apartments_2d.html') # Uncomment this to save it as it's own interactive chart  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the above, but 3D\r\n",
    "fig_3d = px.scatter_3d(pf,\r\n",
    "                    x=\"min_square_footage\", \r\n",
    "                    y=\"min_price\", \r\n",
    "                    z='commute_in_minutes',\r\n",
    "                    color='search_location', \r\n",
    "                    hover_data=['min_ppf', 'model_name']\r\n",
    "                    # hover_data=['residence_name', 'model_name', 'min_ppf', 'commute_in_minutes', 'availability', 'laundry', 'dishwasher', 'pool', 'patio', pf.index]\r\n",
    "                    )\r\n",
    "fig_3d.show()\r\n",
    "# fig_3d.write_html('apartments_3d.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python394jvsc74a57bd00dcdb8eab8d92e27de06b9c5b7d989871148822d0bfdc9493dd7b902c51e7a12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "0dcdb8eab8d92e27de06b9c5b7d989871148822d0bfdc9493dd7b902c51e7a12"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}