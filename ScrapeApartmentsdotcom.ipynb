{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the apartments.com scraping notebook!\r\n",
    "## This notebook does not sort through or clean the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\r\n",
    "import time\r\n",
    "import random\r\n",
    "import requests\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "from datetime import datetime\r\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input desired locations in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with what state you're searching\r\n",
    "state_initials = [\r\n",
    "    'nj',\r\n",
    "    ]\r\n",
    "# Add or remove search locations as needed\r\n",
    "search_locations = [\r\n",
    "    \"somerset\",\r\n",
    "    \"hillsborough\",\r\n",
    "    \"raritan\",\r\n",
    "    \"manville\",\r\n",
    "    \"bound brook\",\r\n",
    "    \"new brunswick\",\r\n",
    "    \"franklin township\",\r\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_firefox_useragent_list():\r\n",
    "    \"\"\"Go to the github page and get the list of firefox user agents\"\"\"\r\n",
    "    ua_page = requests.get('https://raw.githubusercontent.com/tamimibrahim17/List-of-user-agents/master/Firefox.txt') \r\n",
    "    user_agent_list = ua_page.text.split('\\n')\r\n",
    "    return user_agent_list\r\n",
    "\r\n",
    "def hit_page(url, user_agent):\r\n",
    "    \"\"\"Go to the provided url, using the given user agent information\"\"\"\r\n",
    "    page = requests.get(url, headers={'User-Agent': user_agent})\r\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\r\n",
    "    return(soup)\r\n",
    "\r\n",
    "def get_residence_info(residence_info):\r\n",
    "    \"\"\"When we go to the residence page, get the info about the building.\"\"\"\r\n",
    "    residence_name = residence_info.find(id='propertyName').text.strip()\r\n",
    "    residence_address = residence_info.find('div', class_='propertyAddressContainer').find_all('span')[:4]\r\n",
    "    residence_address = [r.text for r in residence_address]\r\n",
    "    residence_address = ' '.join(residence_address)\r\n",
    "    rating = residence_info.find('span', class_='reviewRating')\r\n",
    "    if rating is not None:\r\n",
    "        rating = rating.text.strip()\r\n",
    "    return residence_name, residence_address, rating\r\n",
    "\r\n",
    "def get_apartment_information(apartment_model):\r\n",
    "    \"\"\"Get the information for each apartment listed in the residence\"\"\"\r\n",
    "    model_name = apartment_model.find('span', class_='modelName').text\r\n",
    "    price = apartment_model.find('span', class_='rentLabel').text\r\n",
    "    room_details = [room.text for room in apartment_model.find('span', class_='detailsTextWrapper').find_all('span')]\r\n",
    "    beds = room_details[0]\r\n",
    "    baths = room_details[1]\r\n",
    "    square_footage = room_details[2]\r\n",
    "    details = apartment_model.find('span', class_='detailsTextWrapper leaseDepositLabel').text\r\n",
    "    availability = apartment_model.find('div', class_='availability')\r\n",
    "    if availability is not None:\r\n",
    "        availability = availability.text\r\n",
    "    return model_name, price, beds, baths, square_footage, details, availability\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"Search for the info on each apartment for each residence that we find when searching through our locations.\"\"\"\r\n",
    "\"\"\" \r\n",
    "    Initialize variables and set booleans\r\n",
    "    For each search_location in the set of search_locations:\r\n",
    "        Select a random user agent id\r\n",
    "        Go to the apartments.com results for the search \r\n",
    "        Pull out the set of residences returned by the search\r\n",
    "        For each residence (apartment building) in the set of residences:\r\n",
    "            Find the url for the dedicated residence page\r\n",
    "            Check to see if it's some thing we've seen before\r\n",
    "            If we've seen it, continue to the next, otherwise add it to our list and process it\r\n",
    "            Go to the dedicated page\r\n",
    "            Pull out the information on the residence itself\r\n",
    "            Pull out list of aparment options within each residence\r\n",
    "            For each apartment in the apartments listed:\r\n",
    "                Pull out the details (price, square footage, etc.)\r\n",
    "                Append them to our list of apartment details\r\n",
    "\r\n",
    "Collect everything\r\n",
    "Write csv\r\n",
    "\r\n",
    "Fin\r\n",
    "\"\"\"\r\n",
    "# Initialize and set variables\r\n",
    "talk = True # True prints updates\r\n",
    "visited_links = set()\r\n",
    "all_info = []\r\n",
    "counter = 0\r\n",
    "user_agent_list = get_firefox_useragent_list()\r\n",
    "\r\n",
    "# Iterate through our search locations to get the data for each area.\r\n",
    "for search_location in search_locations:\r\n",
    "\r\n",
    "    if talk == True:\r\n",
    "        print(f\"Searching {search_location} for apartments\")\r\n",
    "\r\n",
    "    # Rotate a series of search locations through the url to collect the search results from each page.\r\n",
    "    # For each location, use a random user agent from our list.\r\n",
    "    user_agent = random.choice(user_agent_list)\r\n",
    "    soup = hit_page(f'https://www.apartments.com/{search_location}-{state_initials}/', user_agent=user_agent)\r\n",
    "    search_results = soup.find(id='placards')\r\n",
    "    residences = search_results.find_all('li', class_='mortar-wrapper')\r\n",
    "    if talk == True:\r\n",
    "        print(\"We found\", len(residences), \"different residences in\", search_location)\r\n",
    "\r\n",
    "\r\n",
    "    for residence in residences:\r\n",
    "\r\n",
    "        # Check to see if this is an apartment we've already seen. If it is, continue on to the next one.\r\n",
    "        # Otherwise add it to the list of links we've hit and proceed to pull the information.\r\n",
    "        link_to_building = residence.find(class_='property-link')['href']\r\n",
    "\r\n",
    "        if (link_to_building in visited_links):\r\n",
    "            continue\r\n",
    "        else:\r\n",
    "            visited_links.add(link_to_building)\r\n",
    "\r\n",
    "        # Wait before hitting the residence page.\r\n",
    "        time.sleep(5)\r\n",
    "        residence_page = hit_page(link_to_building, user_agent=user_agent)\r\n",
    "        \r\n",
    "        # Get the name of the building, it's adress, and the apartments.com rating\r\n",
    "        residence_name, residence_address, rating = get_residence_info(residence_page.find('div', class_='profilePropertyInfoWrapper'))\r\n",
    "\r\n",
    "        # Make an array of the apartment options on the page\r\n",
    "        apartment_options = residence_page.find_all(id='priceGridModelWrapper')\r\n",
    "\r\n",
    "        # For each apartment in our list of options, get the important info\r\n",
    "        for apartment in apartment_options:\r\n",
    "            model_name, price, beds, baths, square_footage, details, availability = get_apartment_information(apartment)\r\n",
    "\r\n",
    "            # Combine all of our information about each option into one array\r\n",
    "            info = [\r\n",
    "                residence_name,\r\n",
    "                model_name,\r\n",
    "                beds,\r\n",
    "                baths,\r\n",
    "                square_footage,\r\n",
    "                price,\r\n",
    "                details,\r\n",
    "                availability,\r\n",
    "                residence_address,\r\n",
    "                link_to_building,\r\n",
    "                search_location,\r\n",
    "            ]\r\n",
    "            if talk == True:\r\n",
    "                print(\"We found the\", model_name, \"at the\", residence_name)\r\n",
    "\r\n",
    "            # Append our array of info about the apartment to our array of arrays\r\n",
    "            all_info.append(info)\r\n",
    "\r\n",
    "    counter = counter + 1\r\n",
    "\r\n",
    "# Convert our array of arrays into a pandas frame\r\n",
    "df = pd.DataFrame(all_info, \r\n",
    "                    columns = ['residence_name', 'model_name', 'beds', 'baths', 'square_footage', 'price', 'details', 'availability', 'residence_address', 'link', 'search_location'])\r\n",
    "\r\n",
    "todays_date = datetime.today().strftime(\"%Y-%m-%d\")\r\n",
    "\r\n",
    "# Choose between saving it in data/scraped_data/ or just data/\r\n",
    "# df.to_csv('data/scraped_data/' + todays_date + '_apartments.csv', index=False)\r\n",
    "df.to_csv('data/' + todays_date + '_apartments.csv', index=False)\r\n",
    "\r\n",
    "# Show us what we found\r\n",
    "df\r\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.4 64-bit",
   "name": "python394jvsc74a57bd00dcdb8eab8d92e27de06b9c5b7d989871148822d0bfdc9493dd7b902c51e7a12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "metadata": {
   "interpreter": {
    "hash": "0dcdb8eab8d92e27de06b9c5b7d989871148822d0bfdc9493dd7b902c51e7a12"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}